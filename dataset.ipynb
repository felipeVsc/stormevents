{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storm Event Data\n",
    "\n",
    "Source: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH',\n",
       "       'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE', 'STATE_FIPS',\n",
       "       'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_FIPS', 'CZ_NAME',\n",
       "       'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME',\n",
       "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
       "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
       "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE',\n",
       "       'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE',\n",
       "       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE',\n",
       "       'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH',\n",
       "       'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
       "       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'DATA_SOURCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"event_details.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202405</td>\n",
       "      <td>23</td>\n",
       "      <td>1947</td>\n",
       "      <td>202405</td>\n",
       "      <td>23</td>\n",
       "      <td>1947</td>\n",
       "      <td>190907</td>\n",
       "      <td>1180619</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>S</td>\n",
       "      <td>FRIENDSHIP</td>\n",
       "      <td>34.6380</td>\n",
       "      <td>-99.2167</td>\n",
       "      <td>34.6380</td>\n",
       "      <td>-99.2167</td>\n",
       "      <td>Two primary rounds of severe convection occurr...</td>\n",
       "      <td>MPing report.</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202411</td>\n",
       "      <td>16</td>\n",
       "      <td>230</td>\n",
       "      <td>202411</td>\n",
       "      <td>18</td>\n",
       "      <td>1421</td>\n",
       "      <td>197838</td>\n",
       "      <td>1223377</td>\n",
       "      <td>OREGON</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A series of cold fronts the weekend of Nov. 16...</td>\n",
       "      <td>The Hog Pass SNOTEL reported an estimated 12 i...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202405</td>\n",
       "      <td>19</td>\n",
       "      <td>1839</td>\n",
       "      <td>202405</td>\n",
       "      <td>19</td>\n",
       "      <td>1902</td>\n",
       "      <td>190905</td>\n",
       "      <td>1184919</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>CUSTER CITY</td>\n",
       "      <td>35.7100</td>\n",
       "      <td>-99.0010</td>\n",
       "      <td>35.7370</td>\n",
       "      <td>-98.8910</td>\n",
       "      <td>Significant severe weather occurred across por...</td>\n",
       "      <td>While the large multiple-vortex tornado was ap...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202405</td>\n",
       "      <td>23</td>\n",
       "      <td>2155</td>\n",
       "      <td>202405</td>\n",
       "      <td>23</td>\n",
       "      <td>2155</td>\n",
       "      <td>190907</td>\n",
       "      <td>1180805</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>W</td>\n",
       "      <td>NINNEKAH</td>\n",
       "      <td>34.9501</td>\n",
       "      <td>-97.9523</td>\n",
       "      <td>34.9501</td>\n",
       "      <td>-97.9523</td>\n",
       "      <td>Two primary rounds of severe convection occurr...</td>\n",
       "      <td>Relayed image showing a portable outbuilding b...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202411</td>\n",
       "      <td>22</td>\n",
       "      <td>400</td>\n",
       "      <td>202411</td>\n",
       "      <td>22</td>\n",
       "      <td>1100</td>\n",
       "      <td>197326</td>\n",
       "      <td>1220680</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>An occluded low pressure system brought heavy ...</td>\n",
       "      <td>A trained spotter reported 10.0 inches of wet ...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           202405         23        1947         202405       23      1947   \n",
       "1           202411         16         230         202411       18      1421   \n",
       "2           202405         19        1839         202405       19      1902   \n",
       "3           202405         23        2155         202405       23      2155   \n",
       "4           202411         22         400         202411       22      1100   \n",
       "\n",
       "   EPISODE_ID  EVENT_ID     STATE  STATE_FIPS  ...  END_RANGE END_AZIMUTH  \\\n",
       "0      190907   1180619  OKLAHOMA          40  ...        4.0           S   \n",
       "1      197838   1223377    OREGON          41  ...        NaN         NaN   \n",
       "2      190905   1184919  OKLAHOMA          40  ...        5.0           N   \n",
       "3      190907   1180805  OKLAHOMA          40  ...        2.0           W   \n",
       "4      197326   1220680  NEW YORK          36  ...        NaN         NaN   \n",
       "\n",
       "  END_LOCATION BEGIN_LAT  BEGIN_LON  END_LAT  END_LON  \\\n",
       "0   FRIENDSHIP   34.6380   -99.2167  34.6380 -99.2167   \n",
       "1          NaN       NaN        NaN      NaN      NaN   \n",
       "2  CUSTER CITY   35.7100   -99.0010  35.7370 -98.8910   \n",
       "3     NINNEKAH   34.9501   -97.9523  34.9501 -97.9523   \n",
       "4          NaN       NaN        NaN      NaN      NaN   \n",
       "\n",
       "                                   EPISODE_NARRATIVE  \\\n",
       "0  Two primary rounds of severe convection occurr...   \n",
       "1  A series of cold fronts the weekend of Nov. 16...   \n",
       "2  Significant severe weather occurred across por...   \n",
       "3  Two primary rounds of severe convection occurr...   \n",
       "4  An occluded low pressure system brought heavy ...   \n",
       "\n",
       "                                     EVENT_NARRATIVE DATA_SOURCE  \n",
       "0                                      MPing report.         CSV  \n",
       "1  The Hog Pass SNOTEL reported an estimated 12 i...         CSV  \n",
       "2  While the large multiple-vortex tornado was ap...         CSV  \n",
       "3  Relayed image showing a portable outbuilding b...         CSV  \n",
       "4  A trained spotter reported 10.0 inches of wet ...         CSV  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Two primary rounds of severe convection occurred on the 23rd, with the first during the initial hours of the morning and the second during the early into late evening. The early morning round was fostered (in part) by a nocturnal low-level jet/ascent across portions of southwestern into south-central Oklahoma. Multiple reports of hail, including a few of severe-caliber, were received with this activity. ||A more impactful round of severe convection emerged by the late afternoon as an upper trough moved into portions of the Plains. Multiple supercell thunderstorms initiated off a dryline near the 100th meridian/far southeastern Texas Panhandle. Strong wind shear, instability and steep lapse rates promoted large to very large hail. As low-level shear increased and an emerging dominant supercell underwent favorable storm-scale interaction(s), significant tornadogenesis occurred. A long-lived and strong tornado occurred across portions of Jackson County, just west of Altus. Additional reports of severe weather were received by late evening from an evolving storm cluster across south-central Oklahoma. An additional supercell thunderstorm produced reports of large hail from the southern into northeastern portions of the Oklahoma City Metropolitan area earlier in the evening.',\n",
       " 'A series of cold fronts the weekend of Nov. 16th lowered snow levels across the region, which brought moderate to heavy snow accumulations across some mountain zones.',\n",
       " 'Significant severe weather occurred across portions of western into central Oklahoma from the late afternoon of the 19th through early morning on the 20th. Aloft, a strong and compact upper wave moved across portions of Kansas during the afternoon. While most severe weather outcomes were expected further north of the WFO Norman area, a few supercell thunderstorms developed along a trailing dryline near the 100th meridian. This included a powerful supercell thunderstorm that moved from Hemphill County, Texas (WFO Amarillo, Texas) into portions of Roger Mills/Custer/Washita/Blaine/Canadian/Oklahoma counties during the afternoon into late evening hours. This thunderstorm was responsible for thirteen (13) tornadoes, including significant tornadoes west of Custer City and near Yukon, Oklahoma. Significant damaging wind gusts/damage and large to very large hail also occurred with this thunderstorm. Additional hail-producing supercells developed into portions of northwestern Oklahoma during the evening, with one becoming briefly tornadic during the late evening across Woods County, Oklahoma.',\n",
       " 'Two primary rounds of severe convection occurred on the 23rd, with the first during the initial hours of the morning and the second during the early into late evening. The early morning round was fostered (in part) by a nocturnal low-level jet/ascent across portions of southwestern into south-central Oklahoma. Multiple reports of hail, including a few of severe-caliber, were received with this activity. ||A more impactful round of severe convection emerged by the late afternoon as an upper trough moved into portions of the Plains. Multiple supercell thunderstorms initiated off a dryline near the 100th meridian/far southeastern Texas Panhandle. Strong wind shear, instability and steep lapse rates promoted large to very large hail. As low-level shear increased and an emerging dominant supercell underwent favorable storm-scale interaction(s), significant tornadogenesis occurred. A long-lived and strong tornado occurred across portions of Jackson County, just west of Altus. Additional reports of severe weather were received by late evening from an evolving storm cluster across south-central Oklahoma. An additional supercell thunderstorm produced reports of large hail from the southern into northeastern portions of the Oklahoma City Metropolitan area earlier in the evening.',\n",
       " 'An occluded low pressure system brought heavy rain on the front end, with a change to heavy wet accumulating snow in higher elevations as the upper level low approached. Their were much lower amounts in lower elevations. The upper low swung through on the back end of the system early on the 22nd resulted in height falls and colder air working in changing the precipitation to mainly wet snow across portions of the interior, especially in elevated locations.',\n",
       " 'A frontal boundary followed by a large area of low pressure sitting just off the coast facilitated heavy snow over the Cascades from Oct 31st to Nov 1st.',\n",
       " 'A frontal boundary followed by a large area of low pressure sitting just off the coast facilitated heavy snow over the Cascades Oct 31 into Nov 1st.',\n",
       " 'An occluded low pressure system brought heavy rain on the front end, with a change to heavy wet accumulating snow in higher elevations as the upper level low approached. Their were much lower amounts in lower elevations. The upper low swung through on the back end of the system early on the 22nd resulted in height falls and colder air working in changing the precipitation to mainly wet snow across portions of the interior, especially in elevated locations.',\n",
       " 'An occluded low pressure system brought heavy rain on the front end, with a change to heavy wet accumulating snow in higher elevations as the upper level low approached. Their were much lower amounts in lower elevations. The upper low swung through on the back end of the system early on the 22nd resulted in height falls and colder air working in changing the precipitation to mainly wet snow across portions of the interior, especially in elevated locations.',\n",
       " 'A cold frontal boundary arriving on Nov 17th followed by a modified arctic airmass loft and long-fetch northwesterly flow by Nov 18th facilitate heavy snow across the Cascades above 2000-3000ft.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./event_details.csv\")\n",
    "df['EPISODE_NARRATIVE'][:10].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hail', 'Heavy Snow', 'Tornado', 'Thunderstorm Wind',\n",
       "       'Winter Weather', 'High Wind', 'Funnel Cloud', 'Heavy Rain',\n",
       "       'Drought', 'Flash Flood', 'Marine Thunderstorm Wind',\n",
       "       'Winter Storm', 'Flood', 'Avalanche', 'Astronomical Low Tide',\n",
       "       'Strong Wind', 'Waterspout', 'Lightning', 'Coastal Flood',\n",
       "       'Blizzard', 'Extreme Cold/Wind Chill', 'Wildfire', 'Heat',\n",
       "       'Debris Flow', 'Lake-Effect Snow', 'Dust Storm', 'Rip Current',\n",
       "       'Dense Fog', 'High Surf', 'Marine High Wind', 'Cold/Wind Chill',\n",
       "       'Ice Storm', 'Frost/Freeze', 'Sneakerwave', 'Freezing Fog',\n",
       "       'Excessive Heat', 'Sleet', 'Marine Hail', 'Dust Devil',\n",
       "       'Tropical Storm', 'Storm Surge/Tide', 'Marine Tropical Storm',\n",
       "       'Hurricane', 'Marine Hurricane/Typhoon', 'Marine Strong Wind',\n",
       "       'Tropical Depression', 'Marine Dense Fog', 'Seiche',\n",
       "       'Marine Tropical Depression', 'Lakeshore Flood'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EVENT_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EVENT_TYPE\n",
       "Thunderstorm Wind             19723\n",
       "Hail                           8932\n",
       "Flash Flood                    4696\n",
       "High Wind                      3448\n",
       "Drought                        3304\n",
       "Heat                           3137\n",
       "Winter Weather                 2979\n",
       "Excessive Heat                 2563\n",
       "Flood                          2368\n",
       "Marine Thunderstorm Wind       2125\n",
       "Heavy Snow                     2056\n",
       "Tornado                        1992\n",
       "Winter Storm                   1981\n",
       "Strong Wind                    1061\n",
       "Heavy Rain                      901\n",
       "Cold/Wind Chill                 730\n",
       "Extreme Cold/Wind Chill         700\n",
       "Dense Fog                       654\n",
       "Tropical Storm                  589\n",
       "Frost/Freeze                    418\n",
       "Coastal Flood                   376\n",
       "Wildfire                        350\n",
       "Blizzard                        320\n",
       "Funnel Cloud                    276\n",
       "Waterspout                      189\n",
       "Lightning                       185\n",
       "Debris Flow                     169\n",
       "High Surf                        99\n",
       "Dust Storm                       87\n",
       "Storm Surge/Tide                 80\n",
       "Hurricane                        78\n",
       "Marine Tropical Storm            76\n",
       "Rip Current                      69\n",
       "Ice Storm                        67\n",
       "Marine High Wind                 56\n",
       "Lake-Effect Snow                 51\n",
       "Tropical Depression              36\n",
       "Avalanche                        23\n",
       "Marine Hail                      22\n",
       "Sneakerwave                      16\n",
       "Marine Hurricane/Typhoon         15\n",
       "Astronomical Low Tide            10\n",
       "Freezing Fog                      7\n",
       "Dust Devil                        7\n",
       "Sleet                             6\n",
       "Marine Strong Wind                3\n",
       "Seiche                            3\n",
       "Marine Dense Fog                  1\n",
       "Marine Tropical Depression        1\n",
       "Lakeshore Flood                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EVENT_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YEARMONTH', 'EPISODE_ID', 'EVENT_ID', 'LOCATION_INDEX', 'RANGE',\n",
       "       'AZIMUTH', 'LOCATION', 'LATITUDE', 'LONGITUDE', 'LAT2', 'LON2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"locations.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEARMONTH</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>LOCATION_INDEX</th>\n",
       "      <th>RANGE</th>\n",
       "      <th>AZIMUTH</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LAT2</th>\n",
       "      <th>LON2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201805</td>\n",
       "      <td>126825</td>\n",
       "      <td>760424</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>N</td>\n",
       "      <td>YORK RIVER EAST REAR RANGE LIGHT WLON (YKRV2)</td>\n",
       "      <td>37.2500</td>\n",
       "      <td>-76.3300</td>\n",
       "      <td>3715000</td>\n",
       "      <td>7619800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201808</td>\n",
       "      <td>130479</td>\n",
       "      <td>780978</td>\n",
       "      <td>2</td>\n",
       "      <td>3.01</td>\n",
       "      <td>SSW</td>\n",
       "      <td>JACKSONVILLE</td>\n",
       "      <td>30.3100</td>\n",
       "      <td>-81.6900</td>\n",
       "      <td>3018600</td>\n",
       "      <td>8141400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201808</td>\n",
       "      <td>130479</td>\n",
       "      <td>780978</td>\n",
       "      <td>3</td>\n",
       "      <td>2.08</td>\n",
       "      <td>SSW</td>\n",
       "      <td>JACKSONVILLE</td>\n",
       "      <td>30.3238</td>\n",
       "      <td>-81.6871</td>\n",
       "      <td>3019428</td>\n",
       "      <td>8141226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201808</td>\n",
       "      <td>130479</td>\n",
       "      <td>780978</td>\n",
       "      <td>4</td>\n",
       "      <td>2.64</td>\n",
       "      <td>SSW</td>\n",
       "      <td>LAKE FOREST</td>\n",
       "      <td>30.3158</td>\n",
       "      <td>-81.6497</td>\n",
       "      <td>3018948</td>\n",
       "      <td>8138982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201808</td>\n",
       "      <td>130476</td>\n",
       "      <td>782301</td>\n",
       "      <td>4</td>\n",
       "      <td>1.52</td>\n",
       "      <td>NW</td>\n",
       "      <td>WEST AUBURN</td>\n",
       "      <td>41.7437</td>\n",
       "      <td>-76.1232</td>\n",
       "      <td>4144622</td>\n",
       "      <td>767392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEARMONTH  EPISODE_ID  EVENT_ID  LOCATION_INDEX  RANGE AZIMUTH  \\\n",
       "0     201805      126825    760424               1   0.00       N   \n",
       "1     201808      130479    780978               2   3.01     SSW   \n",
       "2     201808      130479    780978               3   2.08     SSW   \n",
       "3     201808      130479    780978               4   2.64     SSW   \n",
       "4     201808      130476    782301               4   1.52      NW   \n",
       "\n",
       "                                        LOCATION  LATITUDE  LONGITUDE  \\\n",
       "0  YORK RIVER EAST REAR RANGE LIGHT WLON (YKRV2)   37.2500   -76.3300   \n",
       "1                                   JACKSONVILLE   30.3100   -81.6900   \n",
       "2                                   JACKSONVILLE   30.3238   -81.6871   \n",
       "3                                    LAKE FOREST   30.3158   -81.6497   \n",
       "4                                    WEST AUBURN   41.7437   -76.1232   \n",
       "\n",
       "      LAT2     LON2  \n",
       "0  3715000  7619800  \n",
       "1  3018600  8141400  \n",
       "2  3019428  8141226  \n",
       "3  3018948  8138982  \n",
       "4  4144622   767392  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Fatalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FAT_YEARMONTH', 'FAT_DAY', 'FAT_TIME', 'FATALITY_ID', 'EVENT_ID',\n",
       "       'FATALITY_TYPE', 'FATALITY_DATE', 'FATALITY_AGE', 'FATALITY_SEX',\n",
       "       'FATALITY_LOCATION', 'EVENT_YEARMONTH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"fatalities.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAT_YEARMONTH</th>\n",
       "      <th>FAT_DAY</th>\n",
       "      <th>FAT_TIME</th>\n",
       "      <th>FATALITY_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>FATALITY_TYPE</th>\n",
       "      <th>FATALITY_DATE</th>\n",
       "      <th>FATALITY_AGE</th>\n",
       "      <th>FATALITY_SEX</th>\n",
       "      <th>FATALITY_LOCATION</th>\n",
       "      <th>EVENT_YEARMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202206</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>50284</td>\n",
       "      <td>1131613</td>\n",
       "      <td>D</td>\n",
       "      <td>06/12/2022 00:00:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Permanent Home</td>\n",
       "      <td>202206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202202</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45421</td>\n",
       "      <td>995493</td>\n",
       "      <td>I</td>\n",
       "      <td>02/02/2022 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vehicle/Towed Trailer</td>\n",
       "      <td>202202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202202</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45422</td>\n",
       "      <td>995493</td>\n",
       "      <td>I</td>\n",
       "      <td>02/02/2022 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vehicle/Towed Trailer</td>\n",
       "      <td>202202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202202</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45423</td>\n",
       "      <td>995500</td>\n",
       "      <td>I</td>\n",
       "      <td>02/02/2022 00:00:00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Outside/Open Areas</td>\n",
       "      <td>202202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202202</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>45424</td>\n",
       "      <td>995524</td>\n",
       "      <td>I</td>\n",
       "      <td>02/02/2022 00:00:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Vehicle/Towed Trailer</td>\n",
       "      <td>202202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FAT_YEARMONTH  FAT_DAY  FAT_TIME  FATALITY_ID  EVENT_ID FATALITY_TYPE  \\\n",
       "0         202206       12         0        50284   1131613             D   \n",
       "1         202202        2         0        45421    995493             I   \n",
       "2         202202        2         0        45422    995493             I   \n",
       "3         202202        2         0        45423    995500             I   \n",
       "4         202202        2         0        45424    995524             I   \n",
       "\n",
       "         FATALITY_DATE  FATALITY_AGE FATALITY_SEX      FATALITY_LOCATION  \\\n",
       "0  06/12/2022 00:00:00          77.0            M         Permanent Home   \n",
       "1  02/02/2022 00:00:00           NaN          NaN  Vehicle/Towed Trailer   \n",
       "2  02/02/2022 00:00:00           NaN          NaN  Vehicle/Towed Trailer   \n",
       "3  02/02/2022 00:00:00          18.0            M     Outside/Open Areas   \n",
       "4  02/02/2022 00:00:00          35.0            M  Vehicle/Towed Trailer   \n",
       "\n",
       "   EVENT_YEARMONTH  \n",
       "0           202206  \n",
       "1           202202  \n",
       "2           202202  \n",
       "3           202202  \n",
       "4           202202  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D', 'I'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FATALITY_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FATALITY_LOCATION\n",
       "Unknown                         529\n",
       "Vehicle/Towed Trailer           210\n",
       "Outside/Open Areas              191\n",
       "In Water                        120\n",
       "Permanent Home                   94\n",
       "Mobile/Trailer Home              26\n",
       "Boating                          17\n",
       "Permanent Structure              11\n",
       "Camping                          10\n",
       "Other                             8\n",
       "Under Tree                        5\n",
       "Heavy Equipment/Construction      1\n",
       "Business                          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FATALITY_LOCATION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/details/StormEvents_details-ftp_v1.0_d2019_c20240117.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2011_c20230417.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2018_c20240716.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2000_c20220425.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2012_c20221216.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d1996_c20220425.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2016_c20220719.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35942/1692088515.py:11: DtypeWarning: Columns (26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/details/StormEvents_details-ftp_v1.0_d2001_c20220425.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2020_c20240620.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2010_c20220425.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2021_c20240716.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2023_c20250216.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2004_c20220425.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d1997_c20220425.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35942/1692088515.py:11: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/details/StormEvents_details-ftp_v1.0_d2015_c20240716.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2017_c20250122.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2007_c20240216.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2014_c20231116.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2009_c20231116.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2022_c20241121.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2006_c20250122.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35942/1692088515.py:11: DtypeWarning: Columns (29,34,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/details/StormEvents_details-ftp_v1.0_d2002_c20220425.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2005_c20220425.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2013_c20230118.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2008_c20240620.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d2003_c20220425.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d1998_c20220425.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35942/1692088515.py:11: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/details/StormEvents_details-ftp_v1.0_d2024_c20250216.csv\n",
      "data/details/StormEvents_details-ftp_v1.0_d1999_c20220425.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201905</td>\n",
       "      <td>9</td>\n",
       "      <td>1554</td>\n",
       "      <td>201905</td>\n",
       "      <td>9</td>\n",
       "      <td>1830</td>\n",
       "      <td>137295.0</td>\n",
       "      <td>824116</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NNE</td>\n",
       "      <td>SAN GERONIMO</td>\n",
       "      <td>29.7898</td>\n",
       "      <td>-98.6406</td>\n",
       "      <td>29.7158</td>\n",
       "      <td>-98.7744</td>\n",
       "      <td>Thunderstorms developed along a cold front as ...</td>\n",
       "      <td>Thunderstorms produced heavy rain that led to ...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201908</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>201908</td>\n",
       "      <td>7</td>\n",
       "      <td>1400</td>\n",
       "      <td>141502.0</td>\n",
       "      <td>849617</td>\n",
       "      <td>SOUTH DAKOTA</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>W</td>\n",
       "      <td>BRUCE</td>\n",
       "      <td>44.5400</td>\n",
       "      <td>-96.9600</td>\n",
       "      <td>44.4300</td>\n",
       "      <td>-96.9400</td>\n",
       "      <td>Minor flooding slowly dwindled during early Au...</td>\n",
       "      <td>A continuation of flooding from July, the Big ...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201909</td>\n",
       "      <td>25</td>\n",
       "      <td>1823</td>\n",
       "      <td>201909</td>\n",
       "      <td>25</td>\n",
       "      <td>1825</td>\n",
       "      <td>141998.0</td>\n",
       "      <td>852808</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>S</td>\n",
       "      <td>OCOTILLO</td>\n",
       "      <td>32.8700</td>\n",
       "      <td>-111.8800</td>\n",
       "      <td>32.8788</td>\n",
       "      <td>-111.8750</td>\n",
       "      <td>Scattered thunderstorms developed over the cen...</td>\n",
       "      <td>Scattered thunderstorms developed across the c...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201902</td>\n",
       "      <td>19</td>\n",
       "      <td>2226</td>\n",
       "      <td>201902</td>\n",
       "      <td>19</td>\n",
       "      <td>2350</td>\n",
       "      <td>134941.0</td>\n",
       "      <td>808922</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rain was heavy at times on the 19th, and there...</td>\n",
       "      <td>One-quarter inch of freezing rain was measured...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201902</td>\n",
       "      <td>19</td>\n",
       "      <td>2255</td>\n",
       "      <td>201902</td>\n",
       "      <td>19</td>\n",
       "      <td>2355</td>\n",
       "      <td>134941.0</td>\n",
       "      <td>808923</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rain was heavy at times on the 19th, and there...</td>\n",
       "      <td>One-quarter inch of freezing rain was measured...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           201905          9        1554         201905        9      1830   \n",
       "1           201908          1           0         201908        7      1400   \n",
       "2           201909         25        1823         201909       25      1825   \n",
       "3           201902         19        2226         201902       19      2350   \n",
       "4           201902         19        2255         201902       19      2355   \n",
       "\n",
       "   EPISODE_ID  EVENT_ID         STATE  STATE_FIPS  ...  END_RANGE END_AZIMUTH  \\\n",
       "0    137295.0    824116         TEXAS        48.0  ...        7.0         NNE   \n",
       "1    141502.0    849617  SOUTH DAKOTA        46.0  ...        3.0           W   \n",
       "2    141998.0    852808       ARIZONA         4.0  ...       24.0           S   \n",
       "3    134941.0    808922      ARKANSAS         5.0  ...        NaN         NaN   \n",
       "4    134941.0    808923      ARKANSAS         5.0  ...        NaN         NaN   \n",
       "\n",
       "   END_LOCATION BEGIN_LAT  BEGIN_LON  END_LAT   END_LON  \\\n",
       "0  SAN GERONIMO   29.7898   -98.6406  29.7158  -98.7744   \n",
       "1         BRUCE   44.5400   -96.9600  44.4300  -96.9400   \n",
       "2      OCOTILLO   32.8700  -111.8800  32.8788 -111.8750   \n",
       "3           NaN       NaN        NaN      NaN       NaN   \n",
       "4           NaN       NaN        NaN      NaN       NaN   \n",
       "\n",
       "                                   EPISODE_NARRATIVE  \\\n",
       "0  Thunderstorms developed along a cold front as ...   \n",
       "1  Minor flooding slowly dwindled during early Au...   \n",
       "2  Scattered thunderstorms developed over the cen...   \n",
       "3  Rain was heavy at times on the 19th, and there...   \n",
       "4  Rain was heavy at times on the 19th, and there...   \n",
       "\n",
       "                                     EVENT_NARRATIVE DATA_SOURCE  \n",
       "0  Thunderstorms produced heavy rain that led to ...         CSV  \n",
       "1  A continuation of flooding from July, the Big ...         CSV  \n",
       "2  Scattered thunderstorms developed across the c...         CSV  \n",
       "3  One-quarter inch of freezing rain was measured...         CSV  \n",
       "4  One-quarter inch of freezing rain was measured...         CSV  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "files = glob.glob(\"data/details/*.csv\")\n",
    "\n",
    "details_df_list = []\n",
    "\n",
    "for f in files:\n",
    "    ano = int(f[43:47])\n",
    "    if ano >= 1996:\n",
    "        print(f)\n",
    "        csv = pd.read_csv(f)\n",
    "        details_df_list.append(csv)\n",
    "\n",
    "details_df = pd.concat(details_df_list)\n",
    "\n",
    "details_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1705613\n"
     ]
    }
   ],
   "source": [
    "# Number of rows combined\n",
    "print(len(details_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOURCE\n",
      "<class 'str'>      46377\n",
      "<class 'float'>        6\n",
      "Name: count, dtype: int64\n",
      "       BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  \\\n",
      "1381            199902          2        1700         199902        2   \n",
      "15350           199910          6        1400         199910        6   \n",
      "15351           199910         16         800         199910       16   \n",
      "15352           199910         28        2100         199910       29   \n",
      "15442           199910          6        1400         199910        6   \n",
      "22390           199906         20        2100         199906       20   \n",
      "\n",
      "       END_TIME  EPISODE_ID  EVENT_ID        STATE  STATE_FIPS  ...  \\\n",
      "1381       1700     1500257   5696289  CONNECTICUT           9  ...   \n",
      "15350      1600     2414210   5724315         UTAH          49  ...   \n",
      "15351      2100     2414211   5724316         UTAH          49  ...   \n",
      "15352       900     2414212   5724317         UTAH          49  ...   \n",
      "15442      1600     2414210   5724314         UTAH          49  ...   \n",
      "22390      2100     2408393   5706329     MISSOURI          29  ...   \n",
      "\n",
      "       END_RANGE END_AZIMUTH END_LOCATION BEGIN_LAT  BEGIN_LON END_LAT  \\\n",
      "1381         NaN         NaN   COUNTYWIDE       NaN        NaN     NaN   \n",
      "15350        NaN         NaN          NaN       NaN        NaN     NaN   \n",
      "15351        NaN         NaN          NaN       NaN        NaN     NaN   \n",
      "15352        NaN         NaN          NaN       NaN        NaN     NaN   \n",
      "15442        NaN         NaN          NaN       NaN        NaN     NaN   \n",
      "22390        NaN         NaN     LA MONTE     38.78     -93.43   38.78   \n",
      "\n",
      "      END_LON                                  EPISODE_NARRATIVE  \\\n",
      "1381      NaN  A combination of a nearly stationary warm fron...   \n",
      "15350     NaN  Strong winds ahead of a cold front brought 66 ...   \n",
      "15351     NaN                                                NaN   \n",
      "15352     NaN                                                NaN   \n",
      "15442     NaN  Strong winds ahead of a cold front brought 66 ...   \n",
      "22390  -93.43                                                NaN   \n",
      "\n",
      "                                         EVENT_NARRATIVE DATA_SOURCE  \n",
      "1381                                                 NaN         PDC  \n",
      "15350                                                NaN         PDC  \n",
      "15351  Strong northerly winds behind a cold front bro...         PDC  \n",
      "15352  Finally some decent snow in the mountains, as ...         PDC  \n",
      "15442                                                NaN         PDC  \n",
      "22390  Thunderstorm winds damaged a house and a barn ...         PDC  \n",
      "\n",
      "[6 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "# Trying to fix mixed types in files\n",
    "\n",
    "df = pd.read_csv(\"./data/details/StormEvents_details-ftp_v1.0_d1999_c20220425.csv\")\n",
    "print((df[df.columns[26]].map(type)).value_counts())\n",
    "\n",
    "# df[\"type\"] = df[\"col\"].map(type)\n",
    "\n",
    "# # See how many different types exist\n",
    "# print(df[\"type\"].value_counts())\n",
    "\n",
    "most_common_type = df[df.columns[26]].map(type).mode()[0]\n",
    "mixed_type_rows = df[df[df.columns[26]].map(type) != most_common_type]\n",
    "print(mixed_type_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_df.to_csv('./details_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH',\n",
       "       'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE', 'STATE_FIPS',\n",
       "       'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_FIPS', 'CZ_NAME',\n",
       "       'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME',\n",
       "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
       "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
       "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE',\n",
       "       'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE',\n",
       "       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE',\n",
       "       'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH',\n",
       "       'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
       "       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'DATA_SOURCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Thunderstorms developed along a cold front as ...\n",
       "1        Minor flooding slowly dwindled during early Au...\n",
       "2        Scattered thunderstorms developed over the cen...\n",
       "3        Rain was heavy at times on the 19th, and there...\n",
       "4        Rain was heavy at times on the 19th, and there...\n",
       "                               ...                        \n",
       "46378    Lack of precipitation during April throughout ...\n",
       "46379    Winds gusting up to 70 mph caused widespread d...\n",
       "46380    Winds gusting up to 70 mph caused widespread d...\n",
       "46381    Hail up to an inch in diameter was reported by...\n",
       "46382    Hail up to an inch in diameter was reported by...\n",
       "Name: EPISODE_NARRATIVE, Length: 1937859, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details_df.EPISODE_NARRATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2000_c20220425.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2006_c20250122.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2012_c20221216.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d1996_c20220425.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2017_c20250122.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2016_c20220719.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2011_c20230417.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2024_c20250216.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2019_c20240117.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2015_c20240716.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2021_c20240716.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2022_c20241121.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2010_c20220425.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2020_c20240620.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2003_c20220425.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2013_c20230118.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d1998_c20220425.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2001_c20220425.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2014_c20231116.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2002_c20220425.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2008_c20240620.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d1997_c20220425.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2023_c20250216.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d1999_c20220425.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2007_c20240216.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2005_c20220425.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2018_c20240716.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2009_c20231116.csv\n",
      "data/fatalities/StormEvents_fatalities-ftp_v1.0_d2004_c20220425.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FAT_YEARMONTH</th>\n",
       "      <th>FAT_DAY</th>\n",
       "      <th>FAT_TIME</th>\n",
       "      <th>FATALITY_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>FATALITY_TYPE</th>\n",
       "      <th>FATALITY_DATE</th>\n",
       "      <th>FATALITY_AGE</th>\n",
       "      <th>FATALITY_SEX</th>\n",
       "      <th>FATALITY_LOCATION</th>\n",
       "      <th>EVENT_YEARMONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200009</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1007045</td>\n",
       "      <td>5174317</td>\n",
       "      <td>D</td>\n",
       "      <td>09/05/2000 12:00:00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Permanent Home</td>\n",
       "      <td>200009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200009</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1007047</td>\n",
       "      <td>5158936</td>\n",
       "      <td>D</td>\n",
       "      <td>09/10/2000 12:00:00</td>\n",
       "      <td>88.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Permanent Home</td>\n",
       "      <td>200009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200009</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1007048</td>\n",
       "      <td>5174425</td>\n",
       "      <td>D</td>\n",
       "      <td>09/03/2000 12:00:00</td>\n",
       "      <td>84.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Long Span Roof</td>\n",
       "      <td>200009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200009</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1007049</td>\n",
       "      <td>5158270</td>\n",
       "      <td>D</td>\n",
       "      <td>09/02/2000 12:00:00</td>\n",
       "      <td>66.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Permanent Home</td>\n",
       "      <td>200009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200009</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1007050</td>\n",
       "      <td>5158270</td>\n",
       "      <td>D</td>\n",
       "      <td>09/03/2000 12:00:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Permanent Home</td>\n",
       "      <td>200009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200009</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1007051</td>\n",
       "      <td>5158270</td>\n",
       "      <td>D</td>\n",
       "      <td>09/04/2000 12:00:00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Permanent Home</td>\n",
       "      <td>200009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200009</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1007052</td>\n",
       "      <td>5158270</td>\n",
       "      <td>D</td>\n",
       "      <td>09/07/2000 12:00:00</td>\n",
       "      <td>77.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Permanent Home</td>\n",
       "      <td>200009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200009</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1007053</td>\n",
       "      <td>5158274</td>\n",
       "      <td>D</td>\n",
       "      <td>09/05/2000 12:00:00</td>\n",
       "      <td>46.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Outside/Open Areas</td>\n",
       "      <td>200009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200010</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1007055</td>\n",
       "      <td>5174102</td>\n",
       "      <td>D</td>\n",
       "      <td>10/25/2000 12:00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Vehicle/Towed Trailer</td>\n",
       "      <td>200010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200010</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1007056</td>\n",
       "      <td>5158231</td>\n",
       "      <td>D</td>\n",
       "      <td>10/22/2000 12:00:00</td>\n",
       "      <td>24.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Other</td>\n",
       "      <td>200010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200010</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1007058</td>\n",
       "      <td>5158233</td>\n",
       "      <td>D</td>\n",
       "      <td>10/21/2000 12:00:00</td>\n",
       "      <td>17.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Other</td>\n",
       "      <td>200010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200010</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1007060</td>\n",
       "      <td>5158344</td>\n",
       "      <td>D</td>\n",
       "      <td>10/04/2000 12:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Outside/Open Areas</td>\n",
       "      <td>200010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200010</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1007061</td>\n",
       "      <td>5162111</td>\n",
       "      <td>D</td>\n",
       "      <td>10/05/2000 12:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>F</td>\n",
       "      <td>In Water</td>\n",
       "      <td>200010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200010</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1007063</td>\n",
       "      <td>5157988</td>\n",
       "      <td>D</td>\n",
       "      <td>10/10/2000 12:00:00</td>\n",
       "      <td>34.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Vehicle/Towed Trailer</td>\n",
       "      <td>200010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200010</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1007065</td>\n",
       "      <td>5160933</td>\n",
       "      <td>D</td>\n",
       "      <td>10/23/2000 12:00:00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>M</td>\n",
       "      <td>In Water</td>\n",
       "      <td>200010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>200011</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1007066</td>\n",
       "      <td>5161752</td>\n",
       "      <td>D</td>\n",
       "      <td>11/30/2000 12:00:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Under Tree</td>\n",
       "      <td>200011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200011</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1007068</td>\n",
       "      <td>5160962</td>\n",
       "      <td>D</td>\n",
       "      <td>11/02/2000 12:00:00</td>\n",
       "      <td>51.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Vehicle/Towed Trailer</td>\n",
       "      <td>200011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>200011</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1007070</td>\n",
       "      <td>5161340</td>\n",
       "      <td>D</td>\n",
       "      <td>11/05/2000 12:00:00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Vehicle/Towed Trailer</td>\n",
       "      <td>200011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>200012</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1007071</td>\n",
       "      <td>5161158</td>\n",
       "      <td>D</td>\n",
       "      <td>12/09/2000 12:00:00</td>\n",
       "      <td>44.0</td>\n",
       "      <td>M</td>\n",
       "      <td>Outside/Open Areas</td>\n",
       "      <td>200012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200012</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1007072</td>\n",
       "      <td>5160459</td>\n",
       "      <td>D</td>\n",
       "      <td>12/18/2000 12:00:00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>F</td>\n",
       "      <td>Vehicle/Towed Trailer</td>\n",
       "      <td>200012.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FAT_YEARMONTH  FAT_DAY  FAT_TIME  FATALITY_ID  EVENT_ID FATALITY_TYPE  \\\n",
       "0          200009        5         0      1007045   5174317             D   \n",
       "1          200009       10         0      1007047   5158936             D   \n",
       "2          200009        3         0      1007048   5174425             D   \n",
       "3          200009        2         0      1007049   5158270             D   \n",
       "4          200009        3         0      1007050   5158270             D   \n",
       "5          200009        4         0      1007051   5158270             D   \n",
       "6          200009        7         0      1007052   5158270             D   \n",
       "7          200009        5         0      1007053   5158274             D   \n",
       "8          200010       25         0      1007055   5174102             D   \n",
       "9          200010       22         0      1007056   5158231             D   \n",
       "10         200010       21         0      1007058   5158233             D   \n",
       "11         200010        4         0      1007060   5158344             D   \n",
       "12         200010        5         0      1007061   5162111             D   \n",
       "13         200010       10         0      1007063   5157988             D   \n",
       "14         200010       23         0      1007065   5160933             D   \n",
       "15         200011       30         0      1007066   5161752             D   \n",
       "16         200011        2         0      1007068   5160962             D   \n",
       "17         200011        5         0      1007070   5161340             D   \n",
       "18         200012        9         0      1007071   5161158             D   \n",
       "19         200012       18         0      1007072   5160459             D   \n",
       "\n",
       "          FATALITY_DATE  FATALITY_AGE FATALITY_SEX      FATALITY_LOCATION  \\\n",
       "0   09/05/2000 12:00:00          61.0            M         Permanent Home   \n",
       "1   09/10/2000 12:00:00          88.0            F         Permanent Home   \n",
       "2   09/03/2000 12:00:00          84.0            F         Long Span Roof   \n",
       "3   09/02/2000 12:00:00          66.0            F         Permanent Home   \n",
       "4   09/03/2000 12:00:00          77.0            F         Permanent Home   \n",
       "5   09/04/2000 12:00:00          83.0            F         Permanent Home   \n",
       "6   09/07/2000 12:00:00          77.0            F         Permanent Home   \n",
       "7   09/05/2000 12:00:00          46.0            M     Outside/Open Areas   \n",
       "8   10/25/2000 12:00:00          33.0            F  Vehicle/Towed Trailer   \n",
       "9   10/22/2000 12:00:00          24.0            M                  Other   \n",
       "10  10/21/2000 12:00:00          17.0            F                  Other   \n",
       "11  10/04/2000 12:00:00           6.0            F     Outside/Open Areas   \n",
       "12  10/05/2000 12:00:00          29.0            F               In Water   \n",
       "13  10/10/2000 12:00:00          34.0            M  Vehicle/Towed Trailer   \n",
       "14  10/23/2000 12:00:00          33.0            M               In Water   \n",
       "15  11/30/2000 12:00:00          50.0            M             Under Tree   \n",
       "16  11/02/2000 12:00:00          51.0            M  Vehicle/Towed Trailer   \n",
       "17  11/05/2000 12:00:00          35.0            M  Vehicle/Towed Trailer   \n",
       "18  12/09/2000 12:00:00          44.0            M     Outside/Open Areas   \n",
       "19  12/18/2000 12:00:00          22.0            F  Vehicle/Towed Trailer   \n",
       "\n",
       "    EVENT_YEARMONTH  \n",
       "0          200009.0  \n",
       "1          200009.0  \n",
       "2          200009.0  \n",
       "3          200009.0  \n",
       "4          200009.0  \n",
       "5          200009.0  \n",
       "6          200009.0  \n",
       "7          200009.0  \n",
       "8          200010.0  \n",
       "9          200010.0  \n",
       "10         200010.0  \n",
       "11         200010.0  \n",
       "12         200010.0  \n",
       "13         200010.0  \n",
       "14         200010.0  \n",
       "15         200011.0  \n",
       "16         200011.0  \n",
       "17         200011.0  \n",
       "18         200012.0  \n",
       "19         200012.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "files = glob.glob(\"data/fatalities/*.csv\")\n",
    "\n",
    "fatalities_df_list = []\n",
    "\n",
    "for f in files:\n",
    "    ano = int(f[49:53])\n",
    "    if ano >= 1996:\n",
    "        print(f)\n",
    "        csv = pd.read_csv(f)\n",
    "        fatalities_df_list.append(csv)\n",
    "\n",
    "fatalities_df = pd.concat(fatalities_df_list)\n",
    "\n",
    "fatalities_df.head(n=20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22807\n"
     ]
    }
   ],
   "source": [
    "print(len(fatalities_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatalities_df.to_csv('./fatalities_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/locations/StormEvents_locations-ftp_v1.0_d2004_c20220425.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2012_c20221216.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2015_c20240716.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2021_c20240716.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2011_c20230417.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2010_c20220425.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2023_c20250216.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2008_c20240620.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2006_c20250122.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2014_c20231116.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2018_c20240716.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2002_c20220425.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2017_c20250122.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2024_c20250216.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2005_c20220425.csv\n",
      "data/locations/StormEvents_locations-ftp_v1.0_d2022_c20241121.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEARMONTH</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>LOCATION_INDEX</th>\n",
       "      <th>RANGE</th>\n",
       "      <th>AZIMUTH</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LAT2</th>\n",
       "      <th>LON2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172580</td>\n",
       "      <td>5403822</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHITE OAK</td>\n",
       "      <td>32.53333</td>\n",
       "      <td>-94.86667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172677</td>\n",
       "      <td>5404229</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EAST PALESTINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172678</td>\n",
       "      <td>5404230</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BEAVER FALLS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172679</td>\n",
       "      <td>5404231</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HARMONY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172680</td>\n",
       "      <td>5404232</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>ELDERTON</td>\n",
       "      <td>40.68333</td>\n",
       "      <td>-79.33333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172681</td>\n",
       "      <td>5404233</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOUTH GREENSBURG</td>\n",
       "      <td>40.28333</td>\n",
       "      <td>-79.53333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172682</td>\n",
       "      <td>5404234</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BEAVER</td>\n",
       "      <td>40.68333</td>\n",
       "      <td>-80.33333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172683</td>\n",
       "      <td>5404235</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SARAHSVILLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172684</td>\n",
       "      <td>5404236</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>S</td>\n",
       "      <td>CONNELLSVILLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172753</td>\n",
       "      <td>5404237</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E</td>\n",
       "      <td>NORENE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172753</td>\n",
       "      <td>5404238</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STATESVILLE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172754</td>\n",
       "      <td>5404239</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MT PLEASANT</td>\n",
       "      <td>35.53333</td>\n",
       "      <td>-87.20000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200406</td>\n",
       "      <td>1172755</td>\n",
       "      <td>5404240</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LANTANA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200406</td>\n",
       "      <td>1173914</td>\n",
       "      <td>5406653</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>S</td>\n",
       "      <td>PRINGLE</td>\n",
       "      <td>43.45000</td>\n",
       "      <td>-103.60000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200406</td>\n",
       "      <td>1173914</td>\n",
       "      <td>5406654</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>WNW</td>\n",
       "      <td>HOT SPGS</td>\n",
       "      <td>43.48333</td>\n",
       "      <td>-103.66667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>200406</td>\n",
       "      <td>1173914</td>\n",
       "      <td>5406655</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>W</td>\n",
       "      <td>HOT SPGS</td>\n",
       "      <td>43.43333</td>\n",
       "      <td>-103.51667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200406</td>\n",
       "      <td>1173915</td>\n",
       "      <td>5406656</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WOUNDED KNEE</td>\n",
       "      <td>43.13333</td>\n",
       "      <td>-102.36667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>200406</td>\n",
       "      <td>1173915</td>\n",
       "      <td>5406657</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>SW</td>\n",
       "      <td>BATESLAND</td>\n",
       "      <td>43.01667</td>\n",
       "      <td>-102.25000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>200406</td>\n",
       "      <td>1173916</td>\n",
       "      <td>5406658</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>E</td>\n",
       "      <td>BELLE FOURCHE</td>\n",
       "      <td>44.66667</td>\n",
       "      <td>-103.83333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200406</td>\n",
       "      <td>1174006</td>\n",
       "      <td>5406659</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HURRICANE</td>\n",
       "      <td>38.41667</td>\n",
       "      <td>-82.46667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEARMONTH  EPISODE_ID  EVENT_ID  LOCATION_INDEX  RANGE AZIMUTH  \\\n",
       "0      200406     1172580   5403822               1    NaN     NaN   \n",
       "1      200406     1172677   5404229               1    NaN     NaN   \n",
       "2      200406     1172678   5404230               1    NaN     NaN   \n",
       "3      200406     1172679   5404231               1    NaN     NaN   \n",
       "4      200406     1172680   5404232               1    1.0      SE   \n",
       "5      200406     1172681   5404233               1    NaN     NaN   \n",
       "6      200406     1172682   5404234               1    NaN     NaN   \n",
       "7      200406     1172683   5404235               1    NaN     NaN   \n",
       "8      200406     1172684   5404236               1    6.0       S   \n",
       "9      200406     1172753   5404237               1    1.0       E   \n",
       "10     200406     1172753   5404238               1    NaN     NaN   \n",
       "11     200406     1172754   5404239               1    NaN     NaN   \n",
       "12     200406     1172755   5404240               1    NaN     NaN   \n",
       "13     200406     1173914   5406653               1   10.0       S   \n",
       "14     200406     1173914   5406654               1   10.0     WNW   \n",
       "15     200406     1173914   5406655               1    2.0       W   \n",
       "16     200406     1173915   5406656               1    NaN     NaN   \n",
       "17     200406     1173915   5406657               1    8.0      SW   \n",
       "18     200406     1173916   5406658               1    2.0       E   \n",
       "19     200406     1174006   5406659               1    NaN     NaN   \n",
       "\n",
       "            LOCATION  LATITUDE  LONGITUDE  LAT2  LON2  \n",
       "0          WHITE OAK  32.53333  -94.86667   NaN   NaN  \n",
       "1     EAST PALESTINE       NaN        NaN   NaN   NaN  \n",
       "2       BEAVER FALLS       NaN        NaN   NaN   NaN  \n",
       "3            HARMONY       NaN        NaN   NaN   NaN  \n",
       "4           ELDERTON  40.68333  -79.33333   NaN   NaN  \n",
       "5   SOUTH GREENSBURG  40.28333  -79.53333   NaN   NaN  \n",
       "6             BEAVER  40.68333  -80.33333   NaN   NaN  \n",
       "7        SARAHSVILLE       NaN        NaN   NaN   NaN  \n",
       "8      CONNELLSVILLE       NaN        NaN   NaN   NaN  \n",
       "9             NORENE       NaN        NaN   NaN   NaN  \n",
       "10       STATESVILLE       NaN        NaN   NaN   NaN  \n",
       "11       MT PLEASANT  35.53333  -87.20000   NaN   NaN  \n",
       "12           LANTANA       NaN        NaN   NaN   NaN  \n",
       "13           PRINGLE  43.45000 -103.60000   NaN   NaN  \n",
       "14          HOT SPGS  43.48333 -103.66667   NaN   NaN  \n",
       "15          HOT SPGS  43.43333 -103.51667   NaN   NaN  \n",
       "16      WOUNDED KNEE  43.13333 -102.36667   NaN   NaN  \n",
       "17         BATESLAND  43.01667 -102.25000   NaN   NaN  \n",
       "18     BELLE FOURCHE  44.66667 -103.83333   NaN   NaN  \n",
       "19         HURRICANE  38.41667  -82.46667   NaN   NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "files = glob.glob(\"data/locations/*.csv\")\n",
    "\n",
    "locations_df_list = []\n",
    "\n",
    "for f in files:\n",
    "    ano = int(f[47:51])\n",
    "    if ano >= 1996:\n",
    "        print(f)\n",
    "        csv = pd.read_csv(f)\n",
    "        locations_df_list.append(csv)\n",
    "\n",
    "locations_df = pd.concat(locations_df_list)\n",
    "\n",
    "locations_df.head(n=20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015221\n"
     ]
    }
   ],
   "source": [
    "print(len(locations_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_df.to_csv(\"./locations_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015221\n"
     ]
    }
   ],
   "source": [
    "# Fill information latitude longitude basded on location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning steps\n",
    "\n",
    "1. Fixing data types\n",
    "2. Dropping null values of important columns (some columns will have null values)\n",
    "3. Fill missing locations values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible analysis\n",
    "\n",
    "Maybe do them in python first so we can have a baseline and then use the duckdb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
